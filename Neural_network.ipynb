{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    ea = np.exp(a)\n",
    "    return ea/np.sum(ea,axis=1,keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self,input_size,layers,output_size):\n",
    "        np.random.seed(0)\n",
    "        model = {}\n",
    "        model[\"w1\"] = np.random.randn(input_size,layers[0])\n",
    "        model[\"b1\"] = np.zeros((1,layers[0]))\n",
    "        model[\"w2\"] = np.random.randn(layers[0],layers[1])\n",
    "        model[\"b2\"] = np.zeros((1,layers[1]))\n",
    "        model[\"w3\"] = np.random.randn(layers[1],output_size)\n",
    "        model[\"b3\"] = np.zeros((1,output_size))\n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self,X):\n",
    "        w1,w2,w3 = self.model[\"w1\"],self.model[\"w2\"],self.model[\"w3\"]\n",
    "        b1,b2,b3 = self.model[\"b1\"],self.model[\"b2\"],self.model[\"b3\"]\n",
    "        z1 = np.dot(X,w1)+b1\n",
    "        a1 = np.tanh(z1)\n",
    "        z2 = np.dot(a1,w2)+b2\n",
    "        a2 = np.tanh(z2)\n",
    "        z3 = np.dot(a2,w3)+b3\n",
    "        y_ = softmax(z3)\n",
    "        self.activation_outputs = (a1,a2,y_)\n",
    "        return y_\n",
    "    \n",
    "    def backward(self,x,y,learning_rate = 0.001):\n",
    "        w1,w2,w3 = self.model[\"w1\"],self.model[\"w2\"],self.model[\"w3\"]\n",
    "        a1,a2,y_ = self.activation_outputs\n",
    "        delta3 = y_-y\n",
    "        \n",
    "        dw3 = np.dot(a2.T,delta3)\n",
    "        db3 = np.sum(delta3,axis = 0)\n",
    "        \n",
    "        delta2 = (1-np.square(a2))*np.dot(delta3,w3.T)\n",
    "        dw2 = np.dot(a1.T,delta2)\n",
    "        db2 = np.sum(delta2,axis = 0)\n",
    "        \n",
    "         \n",
    "        delta1 = (1-np.square(a1))*np.dot(delta2,w2.T)\n",
    "        dw1 = np.dot(X.T,delta1)\n",
    "        db1 = np.sum(delta1,axis = 0)\n",
    "        \n",
    "        self.model['w1'] -= learning_rate*dw1\n",
    "        self.model['w2'] -= learning_rate*dw2\n",
    "        self.model['w3'] -= learning_rate*dw3\n",
    "        \n",
    "        self.model['b1'] -= learning_rate*db1\n",
    "        self.model['b2'] -= learning_rate*db2\n",
    "        self.model['b3'] -= learning_rate*db3\n",
    "        \n",
    "    \n",
    "    def predict(self,x):\n",
    "        y_ = self.forward(x)\n",
    "        return np.argmax(y_,axis=1)\n",
    "    \n",
    "    def summary(self):\n",
    "        W1,W2,W3 = self.model['w1'],self.model['w2'],self.model['w3']\n",
    "        a1,a2,y_ = self.activation_outputs\n",
    "        \n",
    "        print(\"W1 \",W1.shape)\n",
    "        print(\"A1 \",a1.shape)\n",
    "        \n",
    "        print(\"W2 \",W2.shape)\n",
    "        print(\"A2 \",a2.shape)\n",
    "        \n",
    "        print(\"W3 \",W3.shape)\n",
    "        print(\"Y_ \",y_.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_oht,p):\n",
    "    l = -np.mean(y_oht*np.log(p))\n",
    "    return l    \n",
    "\n",
    "def one_hot(y,depth):\n",
    "    m = y.shape[0]\n",
    "    y_oht = np.zeros((m, depth))\n",
    "    y_oht[np.arange(m), y] = 1\n",
    "    return y_oht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def training(x,y,model,epochs = 1000):\n",
    "    training_loss = []\n",
    "    classes = len(np.unique(y))\n",
    "    \n",
    "    y_oht = one_hot(y,classes)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        y_ = model.forward(x)\n",
    "        l = loss(y_oht,y_)\n",
    "        model.backward(x,y_oht)\n",
    "        if(math.isnan(l)):\n",
    "            break\n",
    "        training_loss.append(l)\n",
    "    \n",
    "    return training_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\My Pc\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"/Users/My PC/Downloads/Logistic_X_Train.csv\")\n",
    "Y = pd.read_csv(\"/Users/My PC/Downloads/Logistic_Y_Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(input_size = 2,layers = [5,4],output_size =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-3318ff67ceb0>:2: RuntimeWarning: overflow encountered in exp\n",
      "  ea = np.exp(a)\n",
      "<ipython-input-2-3318ff67ceb0>:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return ea/np.sum(ea,axis=1,keepdims=True)\n",
      "<ipython-input-4-dee1bd19edf4>:2: RuntimeWarning: divide by zero encountered in log\n",
      "  l = -np.mean(y_oht*np.log(p))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7775058480497994,\n",
       " 0.7139798931919217,\n",
       " 0.7021396453653441,\n",
       " 0.7989513303901685,\n",
       " 1.6021452322669913,\n",
       " 2.808862624538078,\n",
       " 2.1392900829899237,\n",
       " 2.944523255698065,\n",
       " 2.517017535720683,\n",
       " 3.041285534006741,\n",
       " 2.5646244572617114,\n",
       " 3.000412464782663,\n",
       " 2.60341225203037,\n",
       " 2.9666895093389574,\n",
       " 2.6352786396295076,\n",
       " 2.9387031577625264,\n",
       " 2.661616916580605,\n",
       " 2.915391350485676,\n",
       " 2.6834788044247695,\n",
       " 2.8959255850903647,\n",
       " 2.7016793741524032,\n",
       " 2.8796444883655736,\n",
       " 2.716863840612398,\n",
       " 2.866011895868372,\n",
       " 2.729551118001775,\n",
       " 2.8545884628503626,\n",
       " 2.7401633902820404,\n",
       " 2.8450114670774656,\n",
       " 2.7490470219570113,\n",
       " 2.8369798706201372,\n",
       " 2.7564878911206834,\n",
       " 2.8302429181433406,\n",
       " 2.7627229807383307,\n",
       " 2.8245912132296813,\n",
       " 2.767949360675606,\n",
       " 2.81984959669292,\n",
       " 2.7723312848669006,\n",
       " 2.8158713787274228,\n",
       " 2.776005884125039,\n",
       " 2.812533616602623,\n",
       " 2.7790877848689663,\n",
       " 2.8097332180141015,\n",
       " 2.7816728885991218,\n",
       " 2.807383707855019,\n",
       " 2.7838414843457095,\n",
       " 2.8054125350558374,\n",
       " 2.7856608239034895,\n",
       " 2.803758823299556,\n",
       " 2.787187259998218,\n",
       " 2.802371489058386,\n",
       " 2.7884680261312993,\n",
       " 2.8012076650665123,\n",
       " 2.7895427209723698,\n",
       " 2.800231378614283,\n",
       " 2.7904445480960582,\n",
       " 2.799412442916682,\n",
       " 2.791201352479596,\n",
       " 2.7987255269169906,\n",
       " 2.7918364877669983,\n",
       " 2.79814937466464,\n",
       " 2.7923695423655848,\n",
       " 2.7976661501527107,\n",
       " 2.7928169476308575,\n",
       " 2.7972608874297133,\n",
       " 2.7931924874652103,\n",
       " 2.7969210290660107,\n",
       " 2.793507725427079,\n",
       " 2.7966360387845803,\n",
       " 2.7937723627786855,\n",
       " 2.7963970763469286,\n",
       " 2.793994538689039,\n",
       " 2.7961967246976114,\n",
       " 2.79418108197059,\n",
       " 2.7960287609753793,\n",
       " 2.7943377221965484,\n",
       " 2.7958879643450287,\n",
       " 2.7944692667679214,\n",
       " 2.795769954734574,\n",
       " 2.7945797494326357,\n",
       " 2.7956710575113197,\n",
       " 2.7946725548664504,\n",
       " 2.795588189927924,\n",
       " 2.7947505231789855,\n",
       " 2.795518765838538,\n",
       " 2.7948160375830464,\n",
       " 2.79546061574722,\n",
       " 2.7948710979424023,\n",
       " 2.7954119197230134,\n",
       " 2.7949173824743876,\n",
       " 2.7953711511116968,\n",
       " 2.7949562995162753,\n",
       " 2.795337029307917,\n",
       " 2.7949890309564593,\n",
       " 2.795308480129459,\n",
       " 2.795016568673299,\n",
       " 2.795284602570461,\n",
       " 2.7950397451076414,\n",
       " 2.7952646409074426,\n",
       " 2.7950592589143173,\n",
       " 2.7952479612959893,\n",
       " 2.7950756964845667,\n",
       " 2.795234032135965,\n",
       " 2.7950895500043624,\n",
       " 2.7952224075982612,\n",
       " 2.7951012326067826,\n",
       " 2.795212713804328,\n",
       " 2.795111091085678,\n",
       " 2.795204637231191,\n",
       " 2.795119416563614,\n",
       " 2.7951979149842137,\n",
       " 2.795126453443154,\n",
       " 2.7951923266362155,\n",
       " 2.7951324069181354,\n",
       " 2.795187687381263,\n",
       " 2.7951374492762975,\n",
       " 2.7951838422911606,\n",
       " 2.795141725187984,\n",
       " 2.795180661497314,\n",
       " 2.795145356144429,\n",
       " 2.7951780361488243,\n",
       " 2.7951484441814283,\n",
       " 2.7951758750215783,\n",
       " 2.79515107500499,\n",
       " 2.7951741016741622,\n",
       " 2.7951533206137165,\n",
       " 2.7951726520617277,\n",
       " 2.795155241499695]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training(X,Y,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.79982686 -0.00383313]\n",
      " [-0.7577847   1.0313704 ]\n",
      " [ 1.0368084  -0.3570041 ]\n",
      " ...\n",
      " [ 0.91472363  0.51784855]\n",
      " [-0.8132619   0.6511149 ]\n",
      " [-0.54779714  0.15991242]]\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.read_csv(\"/Users/My PC/Downloads/Logistic_X_Test.csv\")\n",
    "X_test = X_test.to_numpy(dtype='float32')\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(\"output.csv\",\"w\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    header = [\"label\"]\n",
    "    csv_writer.writerow(header)\n",
    "    print(len(X_test))\n",
    "    for i in range(len(X_test)):\n",
    "        csv_writer.writerow([model.predict(X_test[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label\n",
      "0     [0]\n",
      "1     [0]\n",
      "2     [0]\n",
      "3     [0]\n",
      "4     [0]\n",
      "..    ...\n",
      "745   [0]\n",
      "746   [0]\n",
      "747   [0]\n",
      "748   [0]\n",
      "749   [0]\n",
      "\n",
      "[750 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "out = pd.read_csv('output.csv')\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
